{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка Mistral-7B-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e74cabc17547d49f7381707d908f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=device, quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отключение логирования ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.prompts' from '/home/user/Hacks/DigitalBreakthrough-AIAssistant/models/prompts.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import prompts\n",
    "import importlib\n",
    "importlib.reload(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import catboosty\n",
    "import importlib\n",
    "importlib.reload(catboosty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboosty.filter_question(['налоговый вычет можно получить?'], catboosty.model_filter_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инференс с Streaming'ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obscene_words(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        obscene_words = [word.strip().lower() for word in file.readlines()]\n",
    "    return obscene_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_obscene(text, obscene_words):\n",
    "    text_lower = text.lower()\n",
    "    for word in obscene_words:\n",
    "        if word in text_lower:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene_words = load_obscene_words('data/words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, timeout=120)\n",
    "\n",
    "def process(message: str, context: str):\n",
    "    if check_for_obscene(message, obscene_words):\n",
    "        return False\n",
    "    variants = catboosty.pipeline_predict2([message], catboosty.model_cl_category, catboosty.model_cl_answer, catboosty.tfidf_vectorizer)\n",
    "    encodeds = tokenizer.encode(prompts.top_3_prompt(message, variants), return_tensors='pt')\n",
    "    model_inputs = encodeds.to(device)\n",
    "    gen_ids = model.generate(model_inputs, max_new_tokens=100, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(gen_ids)\n",
    "\n",
    "    ans = decoded[0].split('[/INST]')[-1]\n",
    "\n",
    "\n",
    "    encodeds = tokenizer.encode(prompts.get_prompt(message, ans, context), return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "    kwargs = dict(input_ids=model_inputs, streamer=streamer, max_new_tokens=500)\n",
    "\n",
    "    thread = Thread(target=model.generate, kwargs=kwargs)\n",
    "\n",
    "    thread.start()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://83d918f3c02ce8d11c.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://83d918f3c02ce8d11c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "messages = \"\"\n",
    "loyalty = 100\n",
    "def slow_echo(message, history):\n",
    "    global messages, current_state\n",
    "    messages += f\"User: {message}\\n\"\n",
    "    result = process(message, messages)\n",
    "    if result:\n",
    "        history = \"\"\n",
    "        for char in streamer:\n",
    "            history += char\n",
    "            yield history\n",
    "        messages += f\"Assistant: {message}\\n\"\n",
    "    else:\n",
    "        return 'Перевожу на оператора'\n",
    "\n",
    "gr.ChatInterface(slow_echo, css=\"footer {visibility: hidden}\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 04:49:01,082 (__init__.py:1086 MainThread) ERROR - TeleBot: \"Infinity polling exception: A request to the Telegram API was unsuccessful. Error code: 404. Description: Not Found\"\n",
      "2024-04-28 04:49:01,083 (__init__.py:1088 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/__init__.py\", line 1081, in infinity_polling\n",
      "    self.polling(non_stop=True, timeout=timeout, long_polling_timeout=long_polling_timeout,\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/__init__.py\", line 1166, in polling\n",
      "    logger.info('Starting your bot with username: [@%s]', self.user.username)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/__init__.py\", line 293, in user\n",
      "    self._user = self.get_me()\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/__init__.py\", line 1353, in get_me\n",
      "    apihelper.get_me(self.token)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/apihelper.py\", line 201, in get_me\n",
      "    return _make_request(token, method_url)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/apihelper.py\", line 167, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/telebot/apihelper.py\", line 194, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 404. Description: Not Found\n",
      "\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiTelegramException\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/__init__.py:1081\u001b[0m, in \u001b[0;36mTeleBot.infinity_polling\u001b[0;34m(self, timeout, skip_pending, long_polling_timeout, logger_level, allowed_updates, restart_on_change, path_to_watch, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlong_polling_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlong_polling_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlogger_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestart_on_change\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/__init__.py:1166\u001b[0m, in \u001b[0;36mTeleBot.polling\u001b[0;34m(self, non_stop, skip_pending, interval, timeout, long_polling_timeout, logger_level, allowed_updates, none_stop, restart_on_change, path_to_watch)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_change_detector(path_to_watch)\n\u001b[0;32m-> 1166\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting your bot with username: [@\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser\u001b[49m\u001b[38;5;241m.\u001b[39musername)\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreaded:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/__init__.py:293\u001b[0m, in \u001b[0;36mTeleBot.user\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_me\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/__init__.py:1353\u001b[0m, in \u001b[0;36mTeleBot.get_me\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;124;03mA simple method for testing your bot's authentication token. Requires no parameters.\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;124;03mReturns basic information about the bot in form of a User object.\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \n\u001b[1;32m   1350\u001b[0m \u001b[38;5;124;03mTelegram documentation: https://core.telegram.org/bots/api#getme\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m types\u001b[38;5;241m.\u001b[39mUser\u001b[38;5;241m.\u001b[39mde_json(\n\u001b[0;32m-> 1353\u001b[0m     \u001b[43mapihelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_me\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/apihelper.py:201\u001b[0m, in \u001b[0;36mget_me\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    200\u001b[0m method_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetMe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/apihelper.py:167\u001b[0m, in \u001b[0;36m_make_request\u001b[0;34m(token, method_name, method, params, files)\u001b[0m\n\u001b[1;32m    165\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server returned: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(result\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m--> 167\u001b[0m json_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json_result:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/apihelper.py:194\u001b[0m, in \u001b[0;36m_check_result\u001b[0;34m(method_name, result)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiTelegramException(method_name, result, result_json)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_json\n",
      "\u001b[0;31mApiTelegramException\u001b[0m: A request to the Telegram API was unsuccessful. Error code: 404. Description: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     result \u001b[38;5;241m=\u001b[39m process(prompts\u001b[38;5;241m.\u001b[39mget_prompt(message\u001b[38;5;241m.\u001b[39mtext), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     14\u001b[0m     bot\u001b[38;5;241m.\u001b[39mreply_to(message, result)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfinity_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/telebot/__init__.py:1089\u001b[0m, in \u001b[0;36mTeleBot.infinity_polling\u001b[0;34m(self, timeout, skip_pending, long_polling_timeout, logger_level, allowed_updates, restart_on_change, path_to_watch, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger_level \u001b[38;5;129;01mand\u001b[39;00m logger_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[1;32m   1088\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException traceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[0;32m-> 1089\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger_level \u001b[38;5;129;01mand\u001b[39;00m logger_level \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mINFO:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "\n",
    "\n",
    "bot = telebot.TeleBot('SECRET')\n",
    "\n",
    "@bot.message_handler(commands=['start', 'help'])\n",
    "def greet(message):\n",
    "    bot.send_message(message.chat.id, 'Привет! Я бот техподдержки GeekBrains, чем могу помочь?')\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def echo_all(message):\n",
    "    bot.send_chat_action(message.chat.id, 'typing')\n",
    "    result = process(prompts.get_prompt(message.text), 'user').split('[/INST]')[-1].strip()\n",
    "    bot.reply_to(message, result)\n",
    "\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03183fd6684f4bdea25cf8b650f13bac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0a23b064911a4bd8a1d753e9867089e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3900e8951c634f828a66a7e3eea548c1",
       "style": "IPY_MODEL_de50e252ad214162a13e4101d847fc40",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "314ae7b9b9494329afe0c732ed343a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3900e8951c634f828a66a7e3eea548c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "71d3064c3ac046e199fffabe415d5aea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8e4ef53ef3c94b7ba3615d9df3fae85a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_314ae7b9b9494329afe0c732ed343a02",
       "style": "IPY_MODEL_71d3064c3ac046e199fffabe415d5aea",
       "value": " 3/3 [00:34&lt;00:00, 11.33s/it]"
      }
     },
     "8e820a5b6f1443038416a4a1d40d8577": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "98e74cabc17547d49f7381707d908f19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_0a23b064911a4bd8a1d753e9867089e7",
        "IPY_MODEL_afeaae7905154c4783499492988b8898",
        "IPY_MODEL_8e4ef53ef3c94b7ba3615d9df3fae85a"
       ],
       "layout": "IPY_MODEL_03183fd6684f4bdea25cf8b650f13bac"
      }
     },
     "afeaae7905154c4783499492988b8898": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d5a1b9eab7fb4a5cbfe680bfcd8d0a0e",
       "max": 3,
       "style": "IPY_MODEL_8e820a5b6f1443038416a4a1d40d8577",
       "value": 3
      }
     },
     "d5a1b9eab7fb4a5cbfe680bfcd8d0a0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "de50e252ad214162a13e4101d847fc40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
